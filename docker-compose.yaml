version: "3.9"  # Use Compose file format v3.9 (compatible with Docker 20.10+)

services:

  #################################
  # ðŸš€ FastAPI Inference Container
  #################################
  sentiment-api:
    build: .  # Build the image using Dockerfile in the current directory
    container_name: sentiment-api  # Name of the running container
    ports:
      - "8000:8000"  # Map container port 8000 â†’ localhost:8000
    volumes:
      - ./models:/app/models  # Mount local 'models' folder into container (for loading trained model)
    depends_on:
      - mlflow  # Ensure mlflow service starts before this one (only for container startup order)

  ##############################
  # ðŸ§  MLflow Tracking Server
  ##############################
  mlflow:
    image: mlflow/mlflow:latest  # Use official MLflow Docker image from Docker Hub
    container_name: mlflow-server  # Name of the MLflow container
    ports:
      - "5000:5000"  # Map MLflow port to localhost (UI available at http://localhost:5000)
    environment:
      MLFLOW_BACKEND_STORE_URI: sqlite:///mlflow.db  # Use SQLite file as backend metadata store
      MLFLOW_ARTIFACT_ROOT: s3://your-s3-bucket-name/mlflow-artifacts  # Save model artifacts to S3
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}  # Inject AWS credentials from .env or host
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION}
    volumes:
      - ./mlflow.db:/mlflow.db  # Mount local SQLite DB file into container (persists metadata)
      - ~/.aws:/root/.aws       # Mount AWS credentials for S3 access inside container
